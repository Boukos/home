<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Inference and Representation by inf16nyu</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Inference and Representation</h1>
      <h2 class="project-tagline">NYU, CS / CDS. Fall 16  (DS-GA-1005, CSCI-GA.2569) </h2>
      <a href="https://github.com/inf16nyu/home" class="btn">View on GitHub</a>
      <a href="https://github.com/inf16nyu/home/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/inf16nyu/home/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h4>
<a id="course-staff" class="anchor" href="#course-staff" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>Course staff:</em>
</h4>

<table>
<thead>
<tr>
<th></th>
<th>Name</th>
<th>E-mail (@cs.nyu.edu)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Instructor</td>
<td><a href="http://cs.nyu.edu/%7Edsontag/">David Sontag</a></td>
<td>dsontag</td>
</tr>
<tr>
<td>Instructor</td>
<td><a href="http://cims.nyu.edu/%7Ebruna/">Joan Bruna</a></td>
<td>bruna</td>
</tr>
<tr>
<td>TA</td>
<td><a href="http://cs.nyu.edu/%7Erahul/">Rahul Krishnan</a></td>
<td>rahul</td>
</tr>
<tr>
<td>Grader</td>
<td>Aahlad Manas</td>
<td>apm470 {@/at} nyu.edu</td>
</tr>
<tr>
<td>Grader</td>
<td>Alex Nowak</td>
<td>anv273 {@/at} nyu.edu</td>
</tr>
</tbody>
</table>

<h2>
<a id="syllabus" class="anchor" href="#syllabus" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Syllabus</h2>

<p>This graduate level course presents fundamental tools of probabilistic graphical models, with an emphasis on designing and manipulating generative models, and performing inferential tasks when applied to various types of data. </p>

<p>We will study latent variable graphical models (Latent Dirichlet Allocation, Factor Analysis, Gaussian Processes), state-space models for time series (Kalman Filter, HMMs, ARMA), Gibbs Models, Deep generative models (Variational autoencoders, GANs), and causal inference, covering both the methods (exact/approximate inference, sampling algorithms, exponential families) and modeling applications to text, images and medical data.</p>

<h3>
<a id="lecture-location" class="anchor" href="#lecture-location" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lecture Location</h3>

<p>Monday, 5:10-7:00pm, in Warren Weaver Hall 1302</p>

<h3>
<a id="recitationlaboratory-required-for-all-students" class="anchor" href="#recitationlaboratory-required-for-all-students" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://github.com/inf16nyu/home/tree/master/labs">Recitation/Laboratory</a> (required for all students)</h3>

<p>Wednesdays, 7:10-8:00pm in <a href="http://physics.as.nyu.edu/object/physics.directions">Meyer Hall of Physics</a> 121 </p>

<h3>
<a id="office-hours" class="anchor" href="#office-hours" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Office hours</h3>

<p>DS: Mondays, 10:00-11:00am. Location: 60 5th ave, 6th floor, room 613.</p>

<p>JB: Thursdays, 4:00-5:00pm. Location: 60 5th ave, 6th floor, room 612.</p>

<h3>
<a id="grading" class="anchor" href="#grading" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Grading</h3>

<p>problem sets (45%) + midterm exam (25%) + final project (25%) + participation (5%). </p>

<h3>
<a id="piazza" class="anchor" href="#piazza" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Piazza</h3>

<p>We will use <a href="http://piazza.com/nyu/fall2016/dsga1005csciga2569/home">Piazza</a> to answer questions and post announcements about the course. Please sign up <a href="http://piazza.com/nyu/fall2016/dsga1005csciga2569">here</a>. Students' use of Piazza, particularly for adequately answering other students' questions, will contribute toward their participation grade.</p>

<h3>
<a id="online-recordings" class="anchor" href="#online-recordings" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Online recordings</h3>

<p>Most of the lectures and labs' videos will be posted to NYU Classes. Note, however, that class attendance is required.</p>

<h2>
<a id="schedule" class="anchor" href="#schedule" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Schedule</h2>

<table>
<thead>
<tr>
<th>Week</th>
<th>Lecture Date</th>
<th>Topic</th>
<th>Reference</th>
<th>Deliverables</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>9/12</td>
<td>
<strong>Lec1</strong> Intro and Logistics. Bayesian Networks. <a href="https://github.com/inf16nyu/home/blob/master/slides/lecture1.pdf">Slides</a>
</td>
<td>Murphy <a href="http://www.cs.ubc.ca/%7Emurphyk/MLbook/pml-intro-22may12.pdf">Chapter 1</a> (optional; review for most)<br><br><a href="https://people.eecs.berkeley.edu/%7Ejordan/prelims/chapter2.pdf">Notes on Bayesian networks</a> (Sec. 2.1)<br><br><a href="http://pgm.stanford.edu/Algs/page-75.pdf">Algorithm for d-separation</a> (optional)</td>
<td>
<a href="https://github.com/inf16nyu/home/blob/master/hw/ps1.pdf">PS1</a>, due 9/19</td>
</tr>
<tr>
<td>3</td>
<td>9/19</td>
<td>
<strong>Lec2</strong> Undirected Graphical Models. Markov Random Fields. Ising Model. Applications to Statistical Physics. <a href="https://github.com/inf16nyu/home/blob/master/slides/lecture2.pdf">Slides</a>
</td>
<td>
<a href="https://people.eecs.berkeley.edu/%7Ejordan/prelims/chapter2.pdf">Notes on MRFs</a> (Sec. 2.2-2.4)<br><br> <a href="https://people.eecs.berkeley.edu/%7Ejordan/courses/260-spring10/other-readings/chapter8.pdf">Notes on exponential families</a>
</td>
<td>
<a href="https://github.com/inf16nyu/home/blob/master/hw/ps2/ps2.pdf">PS2</a> [<a href="https://github.com/inf16nyu/home/blob/master/hw/ps2/text_data.csv">data</a>], due 9/26</td>
</tr>
<tr>
<td>4</td>
<td>9/26</td>
<td>
<strong>Lec3</strong> Introduction to Inference. Exact Inference. Gibbs Sampling.</td>
<td></td>
<td>PS3, due 10/3</td>
</tr>
<tr>
<td>5</td>
<td>10/3</td>
<td>
<strong>Lec4</strong> Modeling Text Data. Topic Models. Latent Dirichlet Allocation. [Bayesian Non-parametrics].</td>
<td></td>
<td>PS4, due 10/17, Project Proposal, due 10/24</td>
</tr>
<tr>
<td>6</td>
<td>10/10</td>
<td>No lecture (there <em>is</em> lab).</td>
<td></td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>10/17</td>
<td>
<strong>Lec5</strong> Modeling Survey Data. Factor Analysis. PCA. Expectation-Maximization (EM) Algorithm.</td>
<td></td>
<td>PS5, due 10/24</td>
</tr>
<tr>
<td>8</td>
<td>10/24</td>
<td>
<strong>Lec6</strong> Approximate Inference. Markov Chain Monte-Carlo (MCMC).</td>
<td></td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>10/31</td>
<td><strong>Midterm Exam</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>11/7</td>
<td>
<strong>Lec7</strong> Variational Inference. Revisiting EM. Mean Field.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>11/14</td>
<td>
<strong>Lec8</strong> Modeling Time Series Data. Spatial and Spectral models. GPs, ARMA, HMMs, RNNs.</td>
<td></td>
<td>PS6, due 11/21</td>
</tr>
<tr>
<td>12</td>
<td>11/21</td>
<td>
<strong>Lec9</strong> Modeling Structured Outputs. Conditional Random Fields (CRFs). Exponential families. Maximum Entropy Principle. Deep Structured Prediction.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>13</td>
<td>11/28</td>
<td>
<strong>Lec10</strong> Structured Outputs (contd). Dual Decomposition. Integer Linear Programming. Structured SVM.</td>
<td></td>
<td>PS7, due 12/5</td>
</tr>
<tr>
<td>14</td>
<td>12/5</td>
<td>
<strong>Lec11</strong> Causal Inference.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>15</td>
<td>12/12</td>
<td>
<strong>Lec12</strong> Modeling Images and high-dimensional data. Boltzmann Machines. Autoencoders. Variational Autoencoders.</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>12/13</td>
<td>
<strong>Lec13</strong> Modeling Images and high-dimensional data (contd). Deep Auto-regressive Models. Generative Adversarial Networks (GANs).</td>
<td></td>
<td>Project writeup, due 12/16.</td>
</tr>
<tr>
<td>16</td>
<td>12/19</td>
<td>
<strong>Final Day</strong>  Poster Presentations of Final Projects</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h3>
<a id="bibliography" class="anchor" href="#bibliography" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bibliography</h3>

<p>There is no required book. Assigned readings will come from freely-available online material.</p>

<h4>
<a id="core-materials" class="anchor" href="#core-materials" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Core Materials</h4>

<ul>
<li>Kevin Murphy, <a href="http://www.cs.ubc.ca/%7Emurphyk/MLbook/index.html">Machine Learning: a Probabilistic Perspective</a>, MIT Press, 2012. You can read this online for free from <a href="http://site.ebrary.com/lib/nyulibrary/detail.action?docID=10597102">NYU Libraries</a>. We recommend the latest (4th) printing, as earlier editions had many typos. You can tell which printing you have as follows: check the inside cover, below the "Library of Congress" information. If it says "10 9 8 ... 4" you've got the (correct) fourth print.</li>
<li>Daphne Koller and Nir Friedman, <a href="http://pgm.stanford.edu/">Probabilistic Graphical Models: Principles and Techniques</a>, MIT Press, 2009.</li>
<li>Mike Jordan's notes on <a href="https://people.eecs.berkeley.edu/%7Ejordan/prelims/">Probabilistic Graphical Models</a>
</li>
<li>
<a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-438-algorithms-for-inference-fall-2014/lecture-notes/">MIT lecture notes</a> on algorithms for inference.</li>
<li>
<a href="https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/">Probabilistic Programming and Bayesian Methods for Hackers</a> by Cam Davidson Pilon</li>
<li>Trevor Hastie, Rob Tibshirani, and Jerry Friedman, <a href="http://statweb.stanford.edu/%7Etibs/ElemStatLearn/">Elements of Statistical Learning</a>, Second Edition, Springer, 2009. (Can be downloaded as PDF file.)6</li>
<li>David Barber, <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online">Bayesian Reasoning and Machine Learning</a> , Cambridge University Press, 2012. (Can be downloaded as PDF file.)</li>
</ul>

<h4>
<a id="background-on-probability-and-optimization" class="anchor" href="#background-on-probability-and-optimization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background on Probability and Optimization</h4>

<ul>
<li><a href="http://cs229.stanford.edu/section/cs229-prob.pdf">Review notes from Stanford's machine learning class</a></li>
<li>Sam Roweis's <a href="http://cs.nyu.edu/%7Edsontag/courses/ml12/notes/probx.pdf">probability review</a>
</li>
<li>
<a href="http://www.stanford.edu/%7Eboyd/cvxbook/">Convex Optimization</a> by Stephen Boyd and Lieven Vandenberghe.</li>
</ul>

<h4>
<a id="further-reading" class="anchor" href="#further-reading" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Further Reading</h4>

<ul>
<li>Mike Jordan and Martin Wainwright, <a href="https://people.eecs.berkeley.edu/%7Ewainwrig/Papers/WaiJor08_FTML.pdf">Graphical Models, Exponential Families, and Variational Inference</a>
</li>
<li>Shumway and Stoffer <a href="http://www.stat.pitt.edu/stoffer/tsa4/">Time Series Analysis and its Applications: with R examples</a>
</li>
</ul>

<h3>
<a id="academic-honesty" class="anchor" href="#academic-honesty" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Academic Honesty</h3>

<p>We expect you to try solving each problem set on your own. However, when being stuck on a problem, we encourage you to collaborate with other students in the class, subject to the following rules:</p>

<ul>
<li>You may discuss a problem with any student in this class, and work together on solving it. This can involve brainstorming and verbally discussing the problem, going together through possible solutions, but should not involve one student telling another a complete solution.</li>
<li>Once you solve the homework, you must write up your solutions on your own, without looking at other people's write-ups or giving your write-up to others.</li>
<li>In your solution for each problem, you must write down the names of any person with whom you discussed it. This will not affect your grade.</li>
<li>Do not consult solution manuals or other people's solutions from similar courses.</li>
</ul>

<h4>
<a id="late-submission-policy" class="anchor" href="#late-submission-policy" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>Late submission policy</em>
</h4>

<p>During the semester you are allowed at most two extensions on the homework assignment. Each extension is for at most 48 hours and carries a penalty of 25% off your assignment.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/inf16nyu/home">Inference and Representation</a> is maintained by <a href="https://github.com/inf16nyu">inf16nyu</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
