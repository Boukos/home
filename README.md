# Inference and Representations. 
## Instructors: David Sontag and Joan Bruna. 
## NYU, Fall 2016

##Syllabus
This graduate level course presents fundamental tools of probabilistic graphical models, with the goal of performing inferential tasks on various types of data. We will study latent variable graphical models (Latent Dirichlet Allocation, Factor Analysis, Gaussian Processes), state-space models for time series (Kalman Filter, HMMs, ARMA), Gibbs Models and deep generative models (Variational autoencoders, GANs), covering both the methods (exact/approximate inference, sampling algorithms, exponential families) and modeling applications to text, images and medical data.

## (Tentative) Schedule

- **[Lec1]** Intro and Logistics. Bayesian Networks.

- **[Lec2]** Undirected Graphical Models. Markov Random Fields. Ising Model. 

- **[Lec3]** Introduction to Inference. Exact Inference. Gibbs Sampling. Expectation-Maximization (EM) Algorithm.

- **[Lec4]** Modeling Survey Data. Factor Analysis. PCA.  

- **[Lec5]** Modeling Text Data. Topic Models. Bayesian Non-parametrics. Latent Dirichlet Allocation.

- **[Lec6]** Approximate Inference. Markov Chain Monte-Carlo (MCMC).

- **[Lec7]** Exponential Families. Revisiting EM. Variational Inference.

- **[Lec8]** Variational Inference (contd). Maximum Entropy Principle. Applications to Statistical Physics. 

- **[Lec9]** Modeling Structured Outputs. Conditional Random Fields (CRFs). Deep Structured Prediction.

- **[Lec10]** Structured Outputs (contd). Dual Decomposition. Integer Linear Programming. Application to ??

- **[Lec11]** Causal Inference. 

- **[Lec12]** Modeling Images and high-dimensional data. Boltzmann Machines. Autoencoders. Variational Autoencoders. 

- **[Lec13]** Modeling Images and high-dimensional data (contd). Deep Auto-regressive Models. Generative Adversarial Networks (GANs). 






